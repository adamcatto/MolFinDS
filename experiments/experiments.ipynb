{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MolFinDS â€“ Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import nglview\n",
    "from Bio.PDB import *\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from data.preprocessing_helpers import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Settings / Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant paths\n",
    "DATA_PATH = '../data/'\n",
    "RAW_PATH = os.path.join(DATA_PATH, 'raw/')\n",
    "\n",
    "\n",
    "# configure experiments to run; controls which data gets loaded\n",
    "experiments_to_run = {}\n",
    "experiments_to_run['pocket_classification'] = True\n",
    "experiments_to_run['binding_site_prediction'] = True\n",
    "experiments_to_run['search'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Loading\n",
    "\n",
    "This subsection depends on the `experiments_to_run` dictionary in section 2. Depending on which experiments are to be run, this subsection will find a list (in the form of a newline-separated text file in the relevant `data` directory) of structures to load, and run a script to load them into `data/raw/experiment` for the relevant experiment. This will be passed off to the next subsection, which will process the loaded data into formats that can be fed into machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in experiments_to_run.keys():\n",
    "    if experiments_to_run[experiment]:\n",
    "        # check if data has been loaded already, to avoid unecessary loading\n",
    "        with open(os.path.join(DATA_PATH, experiment, 'full_list.txt')) as f:\n",
    "            \n",
    "            num_ids = len(f.readlines())\n",
    "            if len(list(os.listdir(os.path.join(RAW_PATH, experiment)))) >= num_ids:\n",
    "                print(len(list(os.listdir(os.path.join(RAW_PATH, experiment)))))\n",
    "                print(list(os.listdir(os.path.join(RAW_PATH, experiment))))\n",
    "                print(os.path.join(RAW_PATH, experiment))\n",
    "                print('The data for this experiment ' + experiment + ' has been loaded already. Moving on...')\n",
    "                continue\n",
    "        # otherwise load the data\n",
    "        path = os.path.join(DATA_PATH, experiment)\n",
    "        in_file = os.path.join(path, 'full_list.txt')\n",
    "        out_dir = os.path.join(RAW_PATH, experiment)\n",
    "        print(in_file, out_dir)\n",
    "        load_data(path, in_file, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize molecule\n",
    "parser = PDBParser()\n",
    "pdb_filenames = os.listdir(os.path.join(RAW_PATH, 'pocket_classification'))\n",
    "pdb_files = [os.path.join(RAW_PATH, 'pocket_classification', pdb_filename) for pdb_filename in pdb_filenames]\n",
    "print('first file: ' + pdb_files[0])\n",
    "\n",
    "structure = parser.get_structure('x', pdb_files[0])\n",
    "print(list(structure.get_atoms())[5].get_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sample protein mesh with graphein\n",
    "from data.preprocessing_helpers import build_mesh_from_pdb_file\n",
    "\n",
    "mesh = build_mesh_from_pdb_file(pdb_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
